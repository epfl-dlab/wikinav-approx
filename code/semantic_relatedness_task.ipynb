{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import fasttext\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy import stats\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosineSimilarity(vector1, vector2):\n",
    "    if (norm(vector1) * norm(vector2)) == 0:\n",
    "        return 0\n",
    "\n",
    "    return np.dot(vector1, vector2) / (norm(vector1) * norm(vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rankings(fname, model):\n",
    "    groundtruth_ranking = {}; embedding_ranking = {}\n",
    "    for lnum, line in enumerate(tqdm(open(fname))):\n",
    "        if lnum == 0: #Skipping first line, which is the header!\n",
    "            continue\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        src_pid = line[0]; src_ptitle = line[1]\n",
    "        trgt_pid = line[2]; trgt_ptitle = line[3]\n",
    "        mean_score = float(line[4])\n",
    "        if not model.__contains__(src_pid) or not model.__contains__(trgt_pid):\n",
    "            print(f'Either the source: {(src_pid, src_ptitle)} or the target: {(trgt_pid, trgt_ptitle)} is missing!')\n",
    "            continue\n",
    "        src_emb = model.get_word_vector(src_pid); trgt_emb = model.get_word_vector(trgt_pid)\n",
    "        groundtruth_ranking[(int(src_pid), int(trgt_pid), lnum)] = mean_score\n",
    "        embedding_ranking[(int(src_pid), int(trgt_pid), lnum)] = cosineSimilarity(src_emb, trgt_emb)\n",
    "    return groundtruth_ranking, embedding_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank_correlation(groundtruth_ranking, embedding_ranking):\n",
    "    sorted_groundtruth_ranking = [k[2] for k, v in sorted(groundtruth_ranking.items(), key=lambda item: item[1], reverse=True)]\n",
    "    sorted_embedding_ranking = [k[2] for k, v in sorted(embedding_ranking.items(), key=lambda item: item[1], reverse=True)]\n",
    "    rho, pval = stats.spearmanr(sorted_groundtruth_ranking, sorted_embedding_ranking)\n",
    "    return rho, pval, len(groundtruth_ranking), len(embedding_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_write_output(eval_type, fout, emb_type, d, c, rho, pval, num_pairs_gt, num_pairs_emb):\n",
    "    print(f'Spearman Rank Correlation for the WikiSRS {eval_type} task!')\n",
    "    print(f'Embedding Details. InfSource: {emb_type}, Dim: {d}, ContextWindowSize: {c}')\n",
    "    print(f'rho: {rho}, pvalue: {pval}, num_queries_gt: {num_pairs_gt}, num_queries_emb: {num_pairs_emb}')\n",
    "    fout.write(f'{emb_type}\\t{d}\\t{c}\\t{rho}\\t{pval}\\t{num_pairs_gt}\\t{num_pairs_emb}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath(os.path.join(os.getcwd(),os.pardir))\n",
    "PATH_IN = root_dir\n",
    "langlist = ['en', 'ru', 'ja', 'de', 'fr', 'it', 'pl', 'fa']\n",
    "emb_types = ['real_nav', 'gen_clickstream_private', 'gen_clickstream_public', 'gen_graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for lang in langlist:\n",
    "    relatedness_fname = os.path.join(PATH_IN, 'data', 'relatedness', f'{lang}_WikiSRS_relatedness.tsv')\n",
    "    similarity_fname = os.path.join(PATH_IN, 'data', 'relatedness', f'{lang}_WikiSRS_similarity.tsv')\n",
    "    \n",
    "    model_path = os.path.join(PATH_IN, 'data', 'navigation_embeddings', lang)\n",
    "    fout_relatedness_results = open(os.path.join(PATH_IN, 'downstream_tasks', 'relatedness_results', f'{lang}wiki_relatedness.tsv'), \"w\")\n",
    "    fout_similarity_results = open(os.path.join(PATH_IN, 'downstream_tasks', 'relatedness_results', f'{lang}wiki_similarity.tsv'), \"w\")\n",
    "    fout_relatedness_results.write(f'EmbeddingType\\tDimensionality\\tContextWindowSize\\tRankCorrelation\\tPvalue\\tNumQueries_GT\\tNumQueries_Emb\\n')\n",
    "    fout_similarity_results.write(f'EmbeddingType\\tDimensionality\\tContextWindowSize\\tRankCorrelation\\tPvalue\\tNumQueries_GT\\tNumQueries_Emb\\n')\n",
    "\n",
    "    for emb_type in emb_types:\n",
    "        for d in [128]:\n",
    "#             for c in [1,3,5,7]:\n",
    "            for c in [5]:\n",
    "                tmodel = time.time()\n",
    "                model_fname = os.path.join(model_path, f'article_representations_{emb_type}_{d}_{c}.bin')\n",
    "                model = fasttext.load_model(model_fname)\n",
    "                print(f'Loaded model {model_fname} in {time.time()-tmodel} seconds!')\n",
    "\n",
    "                groundtruth_ranking_rel, embedding_ranking_rel = get_rankings(relatedness_fname, model)\n",
    "                rho_rel, pval_rel, num_pairs_gt_rel, num_pairs_emb_rel = get_rank_correlation(groundtruth_ranking_rel, embedding_ranking_rel)\n",
    "                print_and_write_output('relatedness', fout_relatedness_results, emb_type, d, c, rho_rel, pval_rel, num_pairs_gt_rel, num_pairs_emb_rel)\n",
    "                fout_relatedness_results.flush()\n",
    "\n",
    "                groundtruth_ranking_sim, embedding_ranking_sim = get_rankings(similarity_fname, model)\n",
    "                rho_sim, pval_sim, num_pairs_gt_sim, num_pairs_emb_sim = get_rank_correlation(groundtruth_ranking_sim, embedding_ranking_sim)\n",
    "                print_and_write_output('similarity', fout_similarity_results, emb_type, d, c, rho_sim, pval_sim, num_pairs_gt_sim, num_pairs_emb_sim)\n",
    "                fout_similarity_results.flush()\n",
    "\n",
    "    fout_relatedness_results.close()\n",
    "    fout_similarity_results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
